{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02935dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define\n",
    "variable = '' # define varibale for taraining model\n",
    "normalize_data = True # define true to normalize the data or false to used original data\n",
    "scale_ = True # define true for scaling the data or false for not scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f39037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "base_path = ''\n",
    "path = os.path.join(base_path, 'result')\n",
    "file_path = os.path.join(path, 'final_df.csv')\n",
    "plot = os.path.join(path, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "data.rename(columns = {'Unnamed: 0':'datacamp'}, inplace = True) # change the specific column name\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "if normalize_data == True:\n",
    "    data_final = data.drop(columns=['datacamp'],axis=1)\n",
    "    # Square Transform\n",
    "    square_transform = FunctionTransformer(lambda x: x ** 2)\n",
    "    ct = ColumnTransformer(transformers=[['square_transform',square_transform,list(range(len(data_final.columns)))]],remainder='passthrough')\n",
    "    square_X = ct.fit_transform(data_final).copy()\n",
    "    square_X = pd.DataFrame(square_X,columns=list(data_final.columns)).copy()\n",
    "\n",
    "    square_X.insert (0, 'datacamp', data['datacamp'])\n",
    "    data = square_X\n",
    "\n",
    "    # seperate the independent and target variable on training data\n",
    "    x = square_X.drop(columns=[variable, 'datacamp'],axis=1)\n",
    "    y = square_X[variable]\n",
    "else:\n",
    "    # seperate the independent and target variable on training data\n",
    "    x = data.drop(columns=[variable, 'datacamp'],axis=1)\n",
    "    y = data[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "if scale_ == True:\n",
    "    x_scale = scale(x)\n",
    "    y_scale = scale(y)\n",
    "    x_final = pd.DataFrame(x_scale, columns=list(x.columns))\n",
    "    y_final = pd.Series(y_scale)\n",
    "    data = pd.DataFrame({'datacamp': data['datacamp']})\n",
    "    data = data.join(x_final)\n",
    "    data[variable] = y_final\n",
    "else:\n",
    "    x_final = x\n",
    "    y_final = y\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_final, y_final, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the random forest regression model\n",
    "model =  RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "model.fit(X_train,Y_train)\n",
    "\n",
    "# predict y for X test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83569dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac6eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "# metrics.mean_absolute_error(Y_test, y_pred)\n",
    "print(f'mean_squared_error: {metrics.mean_squared_error(Y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ca9c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ploting predicted value and true value of y\n",
    "# define x axis for scatter plot\n",
    "x_axis = []\n",
    "for i in Y_test:\n",
    "    row = data.loc[data[variable] == i]\n",
    "    x_axis.append(row['datacamp'].values[0])\n",
    "\n",
    "# plot scatter plot\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 10] # set the figure size to solve the overlapping ticks problem\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.scatter(x_axis, Y_test, color = 'red', label = f'{variable} Measured')\n",
    "plt.scatter(x_axis, y_pred, color = 'green', label = f'{variable} predicted')\n",
    "plt.title(f'Scatter plot of {variable} predicted and Ntot measured\\n', fontsize=20)\n",
    "plt.xlabel('\\ndata camp', fontsize=15)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(np.arange(1800, 3000, 100), fontsize=12)\n",
    "plt.ylabel(f'{variable}\\n', fontsize=15)\n",
    "plt.margins(0.5)\n",
    "matplotlib.rcParams['legend.fontsize'] = 15\n",
    "plt.legend(loc='best',fancybox=True, shadow=True)\n",
    "plt.grid()\n",
    "plt.savefig(f'{plot}\\pred_vs_true.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe2e735",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09258325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)# Fit the random search model\n",
    "rf_random.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ef6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = abs(test_labels - predictions)\n",
    "    mape = 100 * np.mean(errors / test_labels)\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print(f'R_square: {model.score(test_features, test_labels)}')\n",
    "    print(f'mean_squared_error: {metrics.mean_squared_error(test_labels, predictions)}')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5124fcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, Y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, Y_test)\n",
    "\n",
    "best_random = rf_random.best_estimator_\n",
    "random_accuracy = evaluate(best_random, X_test, Y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d508579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [20, 30, 40, 50, 60, 70],\n",
    "    'max_features': ['sqrt'],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [4, 5, 7],\n",
    "    'n_estimators': [100, 200, 300, 400, 500, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, Y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455de7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "grid_accuracy = evaluate(best_grid, X_train, Y_train)\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a108d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model training\n",
    "model = RandomForestRegressor(n_estimators = 100,\n",
    "                                min_samples_split = 4,\n",
    "                                min_samples_leaf = 1,\n",
    "                                max_features = 'sqrt',\n",
    "                                max_depth = 20,\n",
    "                                bootstrap = True\n",
    "                             )\n",
    "\n",
    "RF_model = model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Feature importance analysis\n",
    "fi = pd.DataFrame({'feature': list(X_train.columns),\n",
    "                   'importance': RF_model.feature_importances_}).\\\n",
    "                    sort_values('importance', ascending = False)\n",
    "\n",
    "fi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841c4291",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = RF_model.score(X_test, Y_test)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa6c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model \n",
    "model_filename = 'final_RF.sav'\n",
    "path = \"\"\n",
    "model_ path = os.path.join(path, model_filename)\n",
    "joblib.dump(RF_model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
