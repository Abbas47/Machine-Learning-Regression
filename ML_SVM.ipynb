{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02935dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a3615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define\n",
    "variable = '' # define varibale for taraining model\n",
    "normalize_data = True # define true to normalize the data or false to used original data\n",
    "scale_ = True # define true for scaling the data or false for not scaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f39037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define path\n",
    "base_path = ''\n",
    "path = os.path.join(base_path, 'result')\n",
    "file_path = os.path.join(path, 'final_df.csv')\n",
    "plot = os.path.join(path, 'plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9fcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "data.rename(columns = {'Unnamed: 0':'datacamp'}, inplace = True) # change the specific column name\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "if normalize_data == True:\n",
    "    data_final = data.drop(columns=['datacamp'],axis=1)\n",
    "    # Square Transform\n",
    "    square_transform = FunctionTransformer(lambda x: x ** 2)\n",
    "    ct = ColumnTransformer(transformers=[['square_transform',square_transform,list(range(len(data_final.columns)))]],remainder='passthrough')\n",
    "    square_X = ct.fit_transform(data_final).copy()\n",
    "    square_X = pd.DataFrame(square_X,columns=list(data_final.columns)).copy()\n",
    "\n",
    "    square_X.insert (0, 'datacamp', data['datacamp'])\n",
    "    data = square_X\n",
    "\n",
    "    # seperate the independent and target variable on training data\n",
    "    x = square_X.drop(columns=[variable, 'datacamp'],axis=1)\n",
    "    y = square_X[variable]\n",
    "else:\n",
    "    # seperate the independent and target variable on training data\n",
    "    x = data.drop(columns=[variable, 'datacamp'],axis=1)\n",
    "    y = data[variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d4541a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling data\n",
    "if scale_ == True:\n",
    "    x_scale = scale(x)\n",
    "    y_scale = scale(y)\n",
    "    x_final = pd.DataFrame(x_scale, columns=list(x.columns))\n",
    "    y_final = pd.Series(y_scale)\n",
    "    data = pd.DataFrame({'datacamp': data['datacamp']})\n",
    "    data = data.join(x_final)\n",
    "    data[variable] = y_final\n",
    "else:\n",
    "    x_final = x\n",
    "    y_final = y\n",
    "\n",
    "# Split dataset into training set and test set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x_final, y_final, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd3ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the SVM regression model\n",
    "kernel_list = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "r2 = []\n",
    "corr = []\n",
    "p_value = []\n",
    "for kernel_ in kernel_list:\n",
    "    # Final SVM model for DS\n",
    "    clf = make_pipeline(StandardScaler(), SVR(kernel=kernel_))\n",
    "\n",
    "    #Creating the model on Training Data\n",
    "    SVM=clf.fit(X_train,Y_train)\n",
    "    prediction=SVM.predict(X_test)\n",
    "\n",
    "    # creating df with predicted value and true value\n",
    "    TestingDataResults=pd.DataFrame(data=X_test, columns=wavelengths)\n",
    "    TestingDataResults['TargetColumn']=Y_test\n",
    "    TestingDataResults['Prediction']=prediction\n",
    "    model_r2 = r2_score(Y_test, prediction)\n",
    "    r2.append(model_r2)\n",
    "    \n",
    "    corr_, value = pearsonr(prediction, Y_test)\n",
    "    corr.append(corr_[0])\n",
    "    p_value.append(value)\n",
    "    \n",
    "df_final = pd.DataFrame()\n",
    "df_final['kernel'] = kernel_list\n",
    "df_final['model_r2'] = r2\n",
    "df_final['corr'] = corr\n",
    "df_final['p_value'] = p_value\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final SVM model for DS\n",
    "clf = make_pipeline(StandardScaler(), SVR(kernel='linear'))\n",
    "\n",
    "#Creating the model on Training Data\n",
    "SVM=clf.fit(X_train,Y_train)\n",
    "prediction=SVM.predict(X_test)\n",
    "\n",
    "#Printing some sample values of prediction\n",
    "TestingDataResults=pd.DataFrame(data=X_test, columns=wavelengths)\n",
    "TestingDataResults['TargetColumn']=Y_test\n",
    "TestingDataResults['Prediction']=prediction\n",
    "TestingDataResults.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc1923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding top 10 important wavelength\n",
    "perm_importance = permutation_importance(SVM, X_test, Y_test)\n",
    "\n",
    "features = np.array(wavelengths)\n",
    "\n",
    "sorted_idx = perm_importance.importances_mean.argsort()\n",
    "sorted_idx_ = sorted_idx[-10:]\n",
    "plt.barh(features[sorted_idx_], perm_importance.importances_mean[sorted_idx_])\n",
    "plt.xlabel(\"Permutation Importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1263b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model \n",
    "model_filename = 'final_SVM.sav'\n",
    "path = \"\"\n",
    "model_ path = os.path.join(path, model_filename)\n",
    "joblib.dump(RF_model, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
